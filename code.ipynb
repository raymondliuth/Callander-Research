{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8b9e833-b762-450c-b15c-a2a46aac56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#Clean Porn Dataset\n",
    "#Tianhao\n",
    "#2021/7/29\n",
    "####\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5595c2e-874b-4578-b4e9-e4b7bc086d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raymo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:221: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "### Read Categories File\n",
    "pornhub_categories = pd.read_excel(r'C:\\Users\\raymo\\Documents\\GitHub\\Callander-Research\\Porn database\\Data\\RAW\\PH_gay\\Categories.xlsx')\n",
    "\n",
    "### Read xlsx File\n",
    "local_path = 'C:/Users/raymo/Documents/GitHub/Callander-Research/Porn database/Data/RAW/PH_gay/' #local path of where the raw data stored\n",
    "\n",
    "store_path = 'C:/Users/raymo/Documents/GitHub/Callander-Research/Porn database/Data/OUTPUT/' #local path of where the output data stored\n",
    "file_names = ['2021-03-07.xlsx','2021-03-14.xlsx','2021-03-21.xlsx','2021-03-28.xlsx','2021-04-04.xlsx','2021-04-18.xlsx'\n",
    "             ,'2021-05-16.xlsx','2021-05-30.xlsx','2021-06-13.xlsx','2021-06-20.xlsx','2021-07-18.xlsx','2021-07-25.xlsx'\n",
    "             ] #file name\n",
    "\n",
    "datasets = {}\n",
    "for file in file_names:\n",
    "    sample = pd.read_excel(local_path+file,engine=None) #read in files\n",
    "    datasets[file] = sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d174e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_excel('C:/Users/raymo/Documents/GitHub/Callander-Research/Porn database/Data/RAW/PH_gay/2021-06-20.xlsx',engine=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2a5ceba8-349d-4846-9b76-966d15aa96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series types\n",
    "#This function convert series into correct types and check any null\n",
    "\n",
    "def convert_types(file_name, data):\n",
    "    copy_data = data.copy()\n",
    "\n",
    "    #extract the viewkeys from pornhub urls\n",
    "    \n",
    "    copy_data[\"url\"] = [i.replace(\"https://www.pornhub.com/view_video.php?viewkey=\",\"\") for i in copy_data[\"url\"]]\n",
    "    \n",
    "    #convert views(str) to int\n",
    "    copy_data[\"views\"] = copy_data[\"views\"].fillna('0')\n",
    "    copy_data[\"views\"] = [int(str(i).replace(',' , '')) for i in copy_data[\"views\"]]\n",
    "    \n",
    "    #convert approval to int\n",
    "    copy_data[\"approval\"] = copy_data[\"approval\"].fillna('0')\n",
    "    copy_data[\"approval\"] = [int(str(i).replace('%',''))/100 for i in copy_data[\"approval\"]]\n",
    "    \n",
    "    \n",
    "    #convert upload_date to date_time\n",
    "    extract_time_str = file_name.replace(\".xlsx\",\"\").split(\"-\")\n",
    "    extract_time = datetime.date(int(extract_time_str[0]),int(extract_time_str[1]),int(extract_time_str[2]))\n",
    "    upload_time = np.array([])\n",
    "    for i in copy_data[\"upload_date\"]:\n",
    "        copy_data[\"upload_date\"] = copy_data[\"upload_date\"].fillna('0 years ago')\n",
    "        temp = i.split(\" \")\n",
    "        if temp[0] == 'Yesterday':\n",
    "            upload_time = np.append(upload_time,extract_time- datetime.timedelta(days= 1))\n",
    "        elif temp[1] == 'week' or temp[1] == 'weeks':\n",
    "            upload_time = np.append(upload_time,extract_time- datetime.timedelta(days= int(temp[0])*7))\n",
    "        elif temp[1] == 'month' or temp[1] == 'months':\n",
    "            upload_time = np.append(upload_time,extract_time- datetime.timedelta(days= int(temp[0])*30))\n",
    "        elif temp[1] == 'year' or temp[1] == 'years':\n",
    "            upload_time = np.append(upload_time,extract_time- datetime.timedelta(days= int(temp[0])*365))\n",
    "        elif temp[1] == 'day' or temp[1] == 'days':\n",
    "            upload_time = np.append(upload_time,extract_time- datetime.timedelta(days= int(temp[0])*1))\n",
    "        else:\n",
    "            upload_time = np.append(upload_time,'')\n",
    "    copy_data[\"upload_date\"] = upload_time\n",
    "    \n",
    "    #Convert all categories into string and check null\n",
    "    copy_data[\"categories\"] = [str(i) for i in copy_data[\"categories\"]]\n",
    "    \n",
    "    #convert approval_pos and neg to int \n",
    "    copy_data[\"approval_pos\"] = copy_data[\"approval_pos\"].fillna('0')\n",
    "    copy_data[\"approval_pos\"] = [int(str(i).replace('%','').replace('K','000')) for i in copy_data[\"approval_pos\"]]\n",
    "    copy_data[\"approval_neg\"] = copy_data[\"approval_neg\"].fillna('0')\n",
    "    copy_data[\"approval_neg\"] = [int(str(i).replace('%','').replace(\".0\",\"\").replace('K','000')) for i in copy_data[\"approval_neg\"]]\n",
    "    \n",
    "    #Calculate True approval rate\n",
    "    copy_data[\"approval\"] = round(copy_data[\"approval_pos\"]/(copy_data[\"approval_pos\"]+copy_data[\"approval_neg\"]),4)\n",
    "    \n",
    "    \n",
    "    #Clean Actors Column\n",
    "    copy_data[\"actors\"] = copy_data[\"actors\"].fillna('')\n",
    "    copy_data[\"actors\"] = [i.replace(\"Pornstars: \",'').replace(\"Suggest \",'').replace(\"\\n \",'')\n",
    "        .replace(\"Thank you for your suggestions! Our team is reviewing them!\",\"\") for i in copy_data[\"actors\"]]\n",
    "    copy_data[\"actors\"] = ['NaN' if i == '' else i for i in copy_data[\"actors\"]]\n",
    "\n",
    "    #clean comment number\n",
    "    copy_data[\"comments_number\"] = copy_data[\"comments_number\"].fillna('0')\n",
    "    copy_data[\"comments_number\"] = [int(i.replace('(','').replace(')','')) for i in copy_data[\"comments_number\"]]\n",
    "    \n",
    "    #get bag of words for categories\n",
    "    categories_data = modify_categories(copy_data)\n",
    "    \n",
    "    #Clean Comments\n",
    "    comments = copy_data[\"comments_text\"].fillna('')\n",
    "    all_comments = []\n",
    "    for c in comments:\n",
    "        c_only = []\n",
    "        temp = c.split(\";\")\n",
    "        for i in temp:\n",
    "            if '\\n' not in i:\n",
    "                c_only.append(i)\n",
    "        all_comments.append(c_only)\n",
    "    for i in np.arange(len(all_comments)):\n",
    "        if all_comments[i] == [\"\"]:\n",
    "            all_comments[i] = []\n",
    "    copy_data[\"comments_text\"] = all_comments\n",
    "    \n",
    "    #create new table for comments\n",
    "    comments_table = pd.DataFrame(columns = ['url','comments_text'])\n",
    "    comments_table['url'] = copy_data[\"url\"]\n",
    "    comments_table['comments_text'] = copy_data[\"comments_text\"]\n",
    "    \n",
    "    \n",
    "    #clean related playlists videostill\n",
    "    temp1 = []\n",
    "    related_list = copy_data[\"related_videos_videostill\"].fillna(\"\")\n",
    "    for i in related_list:\n",
    "        temp1.append(i.split(';'))\n",
    "    copy_data[\"related_videos_videostill\"] = temp1\n",
    "    \n",
    "    #clean related playlists titles related_videos_videostill_alt\n",
    "    temp2 = []\n",
    "    related_list = copy_data[\"related_videos_videostill_alt\"].fillna(\"\")\n",
    "    for i in related_list:\n",
    "        temp2.append(i.split(';'))\n",
    "    copy_data[\"related_videos_videostill_alt\"] = temp2\n",
    "    \n",
    "    #create new table for related playlists\n",
    "    related_videos = pd.DataFrame(columns = ['url','related_videos_videostill','related_videos_videostill_alt'])\n",
    "    related_videos['url'] = copy_data['url']\n",
    "    related_videos['related_videos_videostill'] = temp1\n",
    "    related_videos['related_videos_videostill_alt'] = temp2\n",
    "    \n",
    "    #drop related_videos\n",
    "    copy_data = copy_data.drop(columns = [\"related_playlists\",\"related_playlists_videostill_alt\",\"related_playlists_videostill\",\"related_videos_videostill\",\"related_videos_videostill_alt\",\n",
    "                                          \"related_videos\",\"videostill_image_alt\",\"categories\",\"comments_text\",\"comments_number\"])\n",
    "    \n",
    "    return copy_data,categories_data,related_videos,comments_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3528b2bb-68de-41a8-b61b-f5f1c5d7c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function create the bag of words for categories\n",
    "def modify_categories(data):\n",
    "    new_categories = [i.replace(\"Categories \\n \",\"\").replace(\" \\n Suggest\",\"\") for i in data[\"categories\"]]\n",
    "    bag = np.array([[]])\n",
    "    for fullstring in data[\"categories\"]: \n",
    "        temp = np.array([])\n",
    "        for substring in pornhub_categories[\"Categories\"]:\n",
    "                \n",
    "            if substring in fullstring:\n",
    "                temp = np.append(temp, 1)\n",
    "            elif substring not in fullstring:\n",
    "                temp = np.append(temp, 0)\n",
    "        \n",
    "        bag = np.append(bag,temp)  \n",
    "    bag = bag.reshape(data[\"categories\"].size,pornhub_categories[\"Categories\"].size)\n",
    "    bag = pd.DataFrame(bag,index = data[\"url\"] ,columns = pornhub_categories[\"Categories\"])\n",
    "    return bag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c893a087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>comments_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ph606c9b210339e</td>\n",
       "      <td>[ wow. easily one of the top 10 vids of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ph5db00da91be01</td>\n",
       "      <td>[ Love your chubby body, love to be in between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ph60ace024ad1a7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ph5f7f6e3e7df61</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ph5f2ca9248b63e</td>\n",
       "      <td>[ great video,thanks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>ph6086d8a953051</td>\n",
       "      <td>[ That video I enjoyed watching. It gets your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ph60153fccb8aae</td>\n",
       "      <td>[ Fuck take me from la 7 inch cock ????]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>ph605311083e8f8</td>\n",
       "      <td>[ Hot! Is there more of this guy?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ph5ee4d450bcbc2</td>\n",
       "      <td>[ Wish i was there really hot,  Super hot. Won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ph608895e172190</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 url                                      comments_text\n",
       "0    ph606c9b210339e  [ wow. easily one of the top 10 vids of all ti...\n",
       "1    ph5db00da91be01  [ Love your chubby body, love to be in between...\n",
       "2    ph60ace024ad1a7                                                 []\n",
       "3    ph5f7f6e3e7df61                                                 []\n",
       "4    ph5f2ca9248b63e                              [ great video,thanks]\n",
       "..               ...                                                ...\n",
       "992  ph6086d8a953051  [ That video I enjoyed watching. It gets your ...\n",
       "993  ph60153fccb8aae           [ Fuck take me from la 7 inch cock ????]\n",
       "994  ph605311083e8f8                 [ Hot! Is there more of this guy?]\n",
       "995  ph5ee4d450bcbc2  [ Wish i was there really hot,  Super hot. Won...\n",
       "996  ph608895e172190                                                 []\n",
       "\n",
       "[997 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9b937cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06f2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a891bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "34af36fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for file:  2021-03-07.xlsx  is successful :) \n",
      "Output for file:  2021-03-14.xlsx  is successful :) \n",
      "Output for file:  2021-03-21.xlsx  is successful :) \n",
      "Output for file:  2021-03-28.xlsx  is successful :) \n",
      "Output for file:  2021-04-04.xlsx  is successful :) \n",
      "Output for file:  2021-04-18.xlsx  is successful :) \n",
      "Output for file:  2021-05-16.xlsx  is successful :) \n",
      "Output for file:  2021-05-30.xlsx  is successful :) \n",
      "Output for file:  2021-06-13.xlsx  is successful :) \n",
      "Output for file:  2021-06-20.xlsx  is successful :) \n",
      "Output for file:  2021-07-18.xlsx  is successful :) \n",
      "Output for file:  2021-07-25.xlsx  is successful :) \n"
     ]
    }
   ],
   "source": [
    "#export modified dataset\n",
    "\n",
    "for k in datasets.keys():\n",
    "    # k is the filename (date)\n",
    "    modified = convert_types(k,datasets[k])\n",
    "    #Create a Folder in the path\n",
    "    new_path = store_path + k.replace(\".xlsx\",\"\") + '/'\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "    \n",
    "    #write out excel file\n",
    "    modified[0].to_excel(new_path+\"OUTPUT_\" + k,sheet_name = 'Sheet 1')\n",
    "    modified[1].to_excel(new_path+\"OUTPUT_Categories_\" + k,sheet_name = 'Sheet 1')\n",
    "    modified[2].to_excel(new_path+\"OUTPUT_Related_Videos_\" + k,sheet_name = 'Sheet 1')\n",
    "    modified[3].to_excel(new_path+\"OUTPUT_Comments_\" + k,sheet_name = 'Sheet 1')\n",
    "    print(\"Output for file: \", k, \" is successful :) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "15f118a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function automaticall download video_stillimages \n",
    "#Parameters:\n",
    "#            path: the path of which the picture be store\n",
    "#            data: the whole dataset\n",
    "        \n",
    "def helper(filename,store_path,data):\n",
    "    new_path = store_path + filename.replace(\".xlsx\",\"\") + '/video_stil_images/'\n",
    "    url_keys = convert_types(filename,data)[0][\"url\"]\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "    urls = data[\"videostill_image\"]\n",
    "    for i in np.arange(len(urls)):\n",
    "        if not pd.isna(urls[i]):\n",
    "            r = requests.get(urls[i], allow_redirects=True,stream = True)\n",
    "            open(new_path+ url_keys[i] + '.jpg', 'wb').write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all images\n",
    "for k in datasets.keys():\n",
    "    helper(k,store_path,datasets[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a0abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
